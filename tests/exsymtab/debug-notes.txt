TODO
====

- Write a struct declaration sharing test that uses non-int types, like float or char[10]
- Write tests for extended symbol table traps discussed on May 1
- variable interpolation: function unary() in tccgen.c
- may need to clear the .c field of each sym's type after each context's use
- check for pad entries using pad_findmy_pv or pad_findmy_pvn, then get the sv using PAD_SV

====

break tcc_compile_string
break tcc_relocate_ex
# This is where the interesting parsing stuff happens
break block
break gfunc_call
lib_path=../..

# Probably want to break on decl0

# Try this to break within next():
break /home/dcmertens/projects/tinycc/tccpp.c:3017

# Otherwise, after the first breakpoint above gets tripped, add this:
break next_nomacro_spc

### When I call tcc_add_symbol... ###

# ... I get to relocate_syms() ...
# What is sh_num? ANS: it is SHN_ABS, which is 0xfff1.
# How does it compare to SHN_LORESERVE == 0xff00? ANS: it is greater.
# If it were lower, it would be changed, so in relocate_syms(), the address is not changed.



line 2329 of libtcc.c
int flagless_original = curr_Def->v & ~(SYM_STRUCT | SYM_FIELD | SYM_FIRST_ANOM);



#### April 27 2014

It's been a while since I last looked at this code.

# Catching up

As of right now, there are tests under tests/exsymtab/, and tests 01, and 20 pass. 30 does
not pass. Neither does the overly complex 09, which is copied and unmodified in 40. 50
does not pass either, and a printout of the address of the two functions "fib" and
"fib_of_5" show that they have the *same* address, which is wrong.

To proceed, and to lose as little ground between steps as possible, I am going to proceed
systematically. I will begin by focusing on test 20.

# Getting oriented with test 20

Test 20 defines a struct in one context, copies that context's symbol table, applies that
symbol table to another context, and tries to compile code that uses the struct
definition. The struct "constructor" can be obtained from the first context after
compilation and it runs without trouble. It is possible to ensure it works by manually
unpacking the struct (treating it like a two-element array).

The error message when the second compiler runs into trouble is 
  <string>:3: error: field not found: x
This means that the compiler does not have any trouble with the statement on the previous
line:
  struct point * pt = pt_p;
That suggests that it is able to search for the symbol called "point" in the
extended symbol table and find it. To be sure of this, I added the following lines to the
extended symbol table search found in the vicinity of line 2280 in tccpp.c:
  if (!memcmp("point", p1, len)) printf("Looking for a point with an extended symbol table callback\n");
  				ts = tcc_state->symtab_name_callback(
  					p1, len, tcc_state->symtab_callback_data, 0);
  if (!memcmp("point", p1, len) && ts) printf("Found a point symbol! Returning %d\n", ts);
These if statements print during the compilation stage before the second compilation
croaks. So we can be sure that the system finds the symbol. Furthermore, the printout of
the symbol number suggests that the return value is sensible.

At present, test 20 shows the following problem:

  ############################################################
  # Extended symbol table entries are not correctly queried. #
  ############################################################

How might we test this? I would have to locate where struct data offsets are queried and
then print out some diagnostics whenever we try to access data from the "point" struct.
Where does this occur? Thanks to ack, I found that this error is printed out on line 3954
of tccgen.c

In the vicinity of this error, the type of the struct that we are accessing is stored in
vtop. vtop is an SValue, a struct defined on line 319 of tcc.h. vtop->type is a CType,
a struct defined on line 298 of the same header file. Judging by the usage, the type's
ref slot (vtop->type.ref) is a Sym linked list. The Sym struct is defined on line 329 of
tcc.h. The v field of that struct is what we're looking for, and is the symbol token of
the Sym in question.

The while loop in tccgen.c that precedes the current error checks if any of the members
of the linked list have the same symbol token as the current symbol token, mostly. The
actual symbol token compared is the current symbol token OR'd with SYM_FIELD. Also, the
search through the linked list starts with the *second* element of the list, not the
first. Here are some important questions worth asking:

  Q: What is contained in the first element of the list?
  Q: When the elements of the list are copied in the symbol table copy function, are
     they copied with the correct flags? [ans line 97]
  Q: Is the token symbol for "x" correctly retrieved for this situation?

I can most easily answer the second question first. The symbol copying is contained in
libtcc.c in the vicinity of line 2220. In particular, all flags are split off of the token
symbol in the vicinity of line 2210, then added back after the arithmetic. Every single
symbol is copied and its symbol token updated in this one spot. The ref pointer is
copied further down, in such a way as to refer to the new, copied symbol token.

I now suspect, strongly, that the problem is that the flags are being mishandled
somewhere. Line 2503 of libtcc.c copies over the flags, which seems odd since the
tokenizer does not understand context and cannot differentiate between struct names,
field names, etc. I do not understand the role of these. At any rate, the value SYM_FILED
is OR'd with the symbol token before the comparison, so the return value of the
name-to-token function should probably *not* have that value. Either that, or all such
flags get stripped out at some point:

  Q: Do extra flags such as SYM_FIELD get stripped out from the symbol token after it is
     returned?



#### April 28 2014

New investigations to resolve the questions asked last night. It turns out that the token
for the "x" struct field is never identified in the extended symbol code. This suggests
that there may be a mistake in the code that searches through extended symbols.

To reach this observation, I added the following diagnostic to tccgen.c, line 3954:

 { printf("Could not find token %x\n", tok);
                tcc_error("field not found: %s",  get_tok_str(tok & ~SYM_FIELD, NULL));
 }


#### April 30 2014

Continuing with my previous line of inquiry, I decided to look more closely at the
preprocessor parsing of single-character tokens, such as "x". How are TokenSym structs
allocated for these? Do they get copied by the symbol table copier?

# TokenSym for x?

To answer that question, I look into the token symbol copying in libtcc. Adding this line
to the copy function:

  printf("Just copied token with string %s\n", tok_sym->str);

lets me check for all tokens that get copied. Do we see "x"?

Many, many, many tokens are created, more than I care to know. They are all probably
preprocessor macros, and I should probably find some way to avoid compiling them each
time the compiler gets invoked. At any rate, we *do* have an "x" token, along with a "y"
token.

Why is this odd? It appears that the lookup-by-name code in test_setup.h can find the
"point" and "pt" token symbols, but is unable to find the [x] token symbol.

# TokenSym search

This sugests that the lookup-by-name code is either broken or not called for "x". To
check this, I added this line to the token lookup-by-name function in test_setup.h:

  printf("Looking up token with name [%s]\n", name_to_find);

I also removed diagnostic output to make the output easier to digest. The output is what
I would have expected:

  Looking up token with name [sq_distance_to_pt]
  Looking up token with name [pt_p]
  Looking up token with name [point]
  Looking up token with name [pt]
  Looking up token with name [pt]
  Looking for an x with an extended symbol table callback
  Looking up token with name [x]
  Looking up token with name [sq_distance_to_pt???]

Thus we are indeed asked to find "x", and I am confident that the "x" tokenSym is indeed
copied to the extended symbol table. There must be an issue with the lookup procedure.

To check if the lookup procedure is faulty, I added a printout to the lookup function that
displays all token names that failed, either because the names didn't match or because the
TokenSym is "not shareable".

And there we see it, hidden among scores of similar lines:

  TokenSym with name [x] does not match or is not shareable

which suggests that the TokenSym for "x" is not shareable. This is odd since the TokenSym
for "point" is shareable, apparently. My next step, then, is to test if I can make this
field shareable.

# Shareability

There are two tests I can perform to see if I can get this to work. The first is to try
using a longer name, in case single-letter tokens behave oddly. The second is to look
more closely at the logic for sharable tokens. I will begin with the first idea. To do
this, I simply rename the fields of the struct from "x" and "y" to "xval" and "yval". For
good measure I also changed the names of the arguments to new_point().

Once again, I get this message:

  Looking up token [xval]
  Could not find token 1000046f

So it appears that the members of structs are not shareable, and so lookup_by_name fails
to return the TokenSym for this field.


#### May 1 2014

After looking at the logic for tcc_tokensym_is_shareable, I think I understand more
clearly that the TokenSym's fields that are checked in this function would point to
globally visible things. The function might be better named tcc_tokensym_has_globals.

At any rate, I decided to remove the "is_shareable" check from the lookup_by_name
function in test_setup.h to see if the struct code will properly compile.

HOLY SHIT IT WORKED!!! HURRAY!!! TEST 30 NOW PASSES!!!

And just to make sure that things aren't stupid, I decided to change one of the variable
names back to a single character, and to reuse that token repeatedly. This way single
character tokens as well as repeated use of the same extended token in different contexts
get tested.

Yes, it all works just as it should. :-D

# Potential TokenSym lookup issues

I have a worry about a potential trap in TokenSym lookup by name. This would only reveal
itself when using three contexts.

In context #1, I write a function called "foo". This is a globally accessible thing, so it
gets stored in the TokenSym's function slot. This TokenSym is copied to an extended symbol
table.

In context #2, I include the extended symbol table from context #1 and write a macro
called "foo". The token "foo" is associated with the TokenSym in the first context's
extended symbol table, so that TokenSym (and tok reference) is returned. This globally
accessible thing gets stored in the *original* TokenSym's define slot! Furthermore, when
the extended symbol table is made from context #2, it does not include a TokenSym for
this symbol! The symbol itself should be in this context's list of symbols, so it will be
copied. Potential problems include:

  1) The original TokenSym's direct pointer to the symbol itself will not be updated with
     the creation of the extended symbol table. This will be a potential memory leak.
  2) If context #2 is applied to a later context, the lookup_by_name function will have to
     know to look for tokens in context #1, or it won't find "foo" defined as a macro.
  3) If context #1 is applied to a later context, the "foo" macro slot will already be
     taken, even though the macro was *not* defined in context #1. Thus if we want to have
     two contexts (say #2 and #3) that morph the behavior of the function call with two
     different macro wrappers, we will likely run into trouble.

I need to write tests for all of these, but would like to move to other things first.

# Function declarations

I now turn my attention to shared functions. The test file for this material was test 40.
I have substantially refactored it to provide cleaner tests and testing framework. I have
also renamed it to describe better what it tests.

Currently, it appears that the function declaration itself works correctly. However, as
the test file now clearly indicates, functions from other contexts do not appear to have
the correct address, something I struck upon when examining this problem back in December.
In contrast to December, I now have an automated test that can reliably report this
failure without inducing a segmentation fault.

# Vtables

A test that falls somewhere between struct declaration sharing and function sharing is
function declaration sharing. I can achieve this test most simply by preparing a context
that declares and can assemble a vtable. I can then call the assembly function in the
test code itself, and hand off the tested struct to a second context, which can simply
work with the results. Thus is born test 35.

Unfortunately, test 35 behaves very strangely. Any direct access to the function address
of the struct causes the *compiler* to segfault. To see this, instead of this (erroneous)
definition for 

  void * distance_func_ptr(struct point * pt) {
    return pt->x;
  }

try this one:

  void * distance_func_ptr(struct point * pt) {
    return pt->squared_distance;
  }

The compiler croaks. Dereferencing an integer in a struct works, but apparently not a
function pointer.

# Non-integer struct members

We now reach an interesting question: are ints just a special case? What if I used double
or float members in the struct? Would the code still compile?


#### May 4, 2014

I realized that a less complicated test for functions would be to compile a function
declaration, then share it. This avoids the actual function compilation step and any
associated headache with that. For this, I moved the current test 40 to number 45, and
created test 40-two-contexts-func-decl-share.c. In this test, we have a pre-compiled
function (written directly into the test source code). The declaration for this function
is in the first while a use of that function is in the second. This is essentially a test
of whether simple .h precompilation can work.

IT WORKS! HURRAY!

This means that if I have a C library that has already been compiled, and I then parse a
header for that file, the parsed header context can be effectively shared! Awesome! It
also suggests that if I (1) declare a set of functions in one compilation context, (2)
compile them in a second, and (3) invoke them in a third, then it should also work. Hmm...

Test 42 tests the above idea. Test 45, in contrast, simply compiles a function and then
shares the context that includes the function compilation. In test 42, I have three three
contexts, not just two.

IT WORKS AGAIN! HURRAY!

So this means that I am actually very close to having everything working. We see that if a
block of code is filled with declarations, such as struct declarations and the like, then
I can share it. The problem arises when I have definitions. I suspect that this is just as
much a problem when sharing global variables, since in some sense a compiled function is a
global thing.

In particular, if I really want to have a set of functions or globals available, I can
add (context-specific) global variables and function *pointers*, write an initialization
function for the compiled context that sets those the the appropriate values, and finally
call that initialization function just after the code block has run.

This approach, however, seems rather hackish to me. I would rather simply get the
definitions to work out-of-the-box.

I strongly suspect that this has to do with the nature of the symbol. That is, I suspect
that the originally compiled symbol has a flag indicating that it is a strongly linked
value, which is appropriate for the newly compiled code block. However, when it is used in
any later block, the symbol must be marked as weakly linked. This is my hunch...

To test this hunch, I will try weakening all symbols that get *copied* to the extended
symbol table, by ORing VT_WEAK to the symbol's type.t field (roughly line 2250 in
libtcc.c). With this change, I then need to see if all of the previously passing tests
still pass, and if test 45 suddenly passes, too.

Unfortunately, this change broke test 30 and 35, and did not make test 45 pass. There must
be something else going on.

What if I go the other route, and ensure that the offset (i.e. the symbol's c field) is
zero? This is, ostensibly, the offset of the symbol in the elf symbol table. If the offset
is zero, it should indicate that the symbol has not yet been allocated. Line 460 of
libtcc.c seems to suggest this could work. To find out if this'll work, I will change the
assignment of the .c field in the symbol table copy code so that it is zero. Looking over
how the .c field is used, this seems like it must be far to blunt a tool. However, I will
try it and see if it makes things work...

It sorta works! Not entirely, but somewhat. The weak linkage breaks things, but the
combination makes test 45 pass. Now we have the simple question: is weak linkage
necessary? To answer this question, I simply remove the ORed part of the symbol copy that
I inserted earlier.

Hurray! Now the 40-series tests pass. Unfortunately, the 30-series tests fail, which means
that I need to only set the c field very selectively. Reading through tccgen.c, it looks
as though the c field can contain things such as pointer offsets (for struct members) and
string lengths, among other things. So, I should only set it to zero for very specific
symbols, and otherwise I should copy it.

For a first test, I will see if checking the symbol's type.t field is sufficient. It seems
plausible that this will have the right information.

HURRAY! IT WORKS NOW!

Well, mostly. I just realized that test 35 was hobbled so that it always failed, but at
least it always completed without segfaulting. Now, if I unhobble test 35, it segfaults
for reasons I do not yet understand. This means that vtable declarations do not yet work
correctly. However, all of the other functionality, including function declaration
sharing, now works! Awesome!

More work lies ahead, but these are major milestones! :-D

#### May 16, 2014

I have spent quite a bit of time working on the Perl bindings to this library. I kept
encountering trouble, but they gave me enough insight to dig back into the libtcc side of
things. I finally figured out that anonymous symbols are not copied to the symbol table,
and that they had to be copied on their own. I figured out the intricacies of what
information is used in which context, and only copying the right stuff at the right time.
Now, I am pretty sure that function signatures, even complex ones, are copied correctly.

As such, now the un-hobbled test 35 passes! HURRAY!!!!

My bindings for libperl still do not work, but I think I have made significant strides on
getting the tcc symbol table copying up and running.

#### Fall, 2014

Been a little while. Let's see if I can figure out where I left off.

I remember that some segfaults in C::Blocks inspired a set of tests, specifically those in
test 28. My other recent commits before putting the project aside include test 51 and 70.
(Test 29 is identical to 28; I'm not quite sure what I had intended to do with that.)

Test 28 segfaults. It creates a context in which it #defines macros. It creates a second
context that consumes the first by creating new macros that depend upon those defined in
the first. Finally, it creates a third context that uses the macros defined in the second
context. (This is analogous to a C::Blocks-based library that creates some macros which
themselves use the Perl C API, implemented using macros.) The segfault occurs during the
compilation of the third context.

Test 51 passes. It defines a function in one context and uses it in later contexts
without declaring it. This may just be tcc defaulting to integer inputs and outputs for
unknown functions, or it may indicate that the function declaration is being properly
shared.

Test 70 fails three of its 67 tests. The three failing tests all occur with the c field
of the function Sym, which is expected to be zero, but is set to 3 after being used in a
dependent context. I seem to recall that the value of c means that the definition is
given externally, which means that the compiler doesn't look up the definition's function
pointer address. I'd prefer if the compiler looked it up; otherwise it's one more thing
that the compilation manager has to wrestle with.

So I paused work on this project with two open questions: (1) Why does deep macro use
lead to segfaults? (2) Why does a consuming context modify the c field of a function Sym?

#### September 4, 2014

To help answer these questions, I created a new make file extension, .gdb. Now when I try
to make a test and set the extension to .gdb, it'll compile and run the executable under
gdb.

Doing so revealed the following problem with test 28:

  Program received signal EXC_BAD_ACCESS, Could not access memory.
  Reason: KERN_INVALID_ADDRESS at address: 0x0000000000000000
  pstrcpy (buf=0x7fff5fbfe62f " ", buf_size=1025, s=0x0) at libtcc.c:144
  144	            c = *s++;

#### September 5, 2014

Hmmm, that's a string copy starting from a null address. Here's the stack trace:

#0  pstrcpy (buf=0x7fff5fbfe62f " ", buf_size=1025, s=0x0) at libtcc.c:144
#1  0x0000000100008af7 in TOK_GET [inlined] () at /Users/dcmertens/projects/Perl/tinycc/tccpp.c:1015
#2  0x0000000100008af7 in macro_is_equal [inlined] () at /Users/dcmertens/projects/Perl/tinycc/tccpp.c:1016
#3  0x0000000100008af7 in define_push (v=1606411823, macro_type=1606412896, str=0x7fff5fbfea60, first_arg=0x7fff5fbfea60) at tccpp.c:1029
#4  0x000000010000ac6a in parse_define () at tccpp.c:1294
#5  0x0000000100009b90 in is_space [inlined] () at /Users/dcmertens/projects/Perl/tinycc/tcc.h:1412
#6  0x0000000100009b90 in preprocess (is_bof=1606415152) at tccpp.c:2580
#7  0x000000010000b338 in next_nomacro1 () at tccpp.c:2216
#8  0x0000000100008ed5 in next_nomacro [inlined] () at /Users/dcmertens/projects/Perl/tinycc/tccpp.c:2579
#9  0x0000000100008ed5 in next () at tccpp.c:3016
#10 0x00000001000035ca in tcc_compile (s1=0x100802c00) at libtcc.c:794
#11 0x0000000100003be3 in tcc_compile_string (s=0x100802c00, str=0x100039458 "#define add_foo_and_var_to(val) (foo + add_var_to(val))\n") at libtcc.c:849
#12 0x0000000100001197 in main (argc=2, argv=0x7fff5fbff992) at 28-three-contexts-intertwined-preprocessor-macro.c:98

I'm 99% certain that the copy from the null address is due to now knowing where to find
add_var_to().
